{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data integration\n",
    "\n",
    "### URLs\n",
    "- https://github.com/jorisvandenbossche/2015-PyDataParis\n",
    "\n",
    "### Working with a Pandas dataframe\n",
    "\n",
    "<img src=\"https://github.com/FIIT-IAU/2015-PyDataParis/raw/b900fdb9f3c12e9206bb417022dd004abf023c0f/img/dataframe.png\" width=\"50%\" height=\"50%\" />\n",
    "\n",
    "\n",
    "# Case study: Air quality in Europe\n",
    "**[European air quality information reported by EEA member countries](https://www.eea.europa.eu/data-and-maps/data#c0=5&c11=&c5=all&b_start=0).**\n",
    "\n",
    "AirBase (The European Air quality dataBase): hourly measurements of all air quality monitoring stations from Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/input/BETR8010000800100hour.1-1-1990.31-12-2012\"\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are several problems with loading. So let's try looking at the data in some editor before we load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head data/input/BETR8010000800100hour.1-1-1990.31-12-2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we know about this so far is that it will be a **csv format, the value separator is \\t**, there are only numerical data and we do not have named attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lh data/input/BETR8010000800100hour.1-1-1990.31-12-2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "wc -l data/input/BETR8010000800100hour.1-1-1990.31-12-2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the data is not that much and I don't have to worry about loading it all into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename, \n",
    "                   sep='\\t', \n",
    "                   header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 49 columns. Date and 48 other numeric attributes. Everyone else seems to be binary. Probably some symptom.\n",
    "\n",
    "The data are made up of measurements of some quantity in about individual hours of the day. \n",
    "\n",
    "What a day, what a line. Each hour has a separate column + there is a column for some symptom that we are not interested in now.\n",
    "\n",
    "There are some weird values ​​that probably shouldn't be there: -999 and -9999.\n",
    "\n",
    "The date will probably be an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename, \n",
    "                   sep='\\t', \n",
    "                   header=None,\n",
    "                   na_values=[-999, -9999], \n",
    "                   index_col=0\n",
    "                  )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will try to discard those flags that do not interest us. Coincidentally, it is every other column\n",
    "data.columns[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[1::2], \n",
    "                 axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to name the resulting columns in a normal way\n",
    "[\"{:02d}\".format(i) for i in range(len(data.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have the names of the columns scattered somehow\n",
    "data.columns = [\"{:02d}\".format(i) for i in range(len(data.columns))]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try to move each measurement to a separate line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.stack()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result of the rearrangement is a multidimensional Series object, not a DataFrame.\n",
    "type(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could give the column a normal name, e.g. by the name of the measuring station, which is in the file name\n",
    "_, fname = os.path.split(filename)\n",
    "station = fname[:7]\n",
    "print(filename)\n",
    "print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index turns it into a data frame for me\n",
    "data = data.reset_index(name=station) \n",
    "# data = data.reset_index()\n",
    "\n",
    "print(type(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {0:'date', 'level_1':'hour'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will create a new index for it from the date and time\n",
    "data.index = pd.to_datetime(data['date'] + ' ' + data['hour'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary columns\n",
    "data = data.drop(['date', 'hour'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Above-code for one station is inserted into the python file `airbase.py`\n",
    "**We are going to work with more stations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airbase\n",
    "no2 = airbase.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot can also show outliers\n",
    "# sns.boxplot(no2, sym='k.')\n",
    "sns.boxplot(data=no2, sym='k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2['BETN029'].plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=no2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plotting\n",
    "no2.plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can say that I only want a smaller part\n",
    "no2[-500:].plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Or I will use more interesting operations with timeseries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the index is times, I can do interesting things with them\n",
    "no2.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, define ranges using a string with a date\n",
    "no2[\"2010-01-01 09:00\": \"2010-01-01 12:00\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or to select all data from one specific year in this way\n",
    "no2.loc['2012']\n",
    "# no2['2012']\n",
    "# no2['2012'].head()\n",
    "\n",
    "# or just data from March\n",
    "# no2['2012/03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date components are accessible from the index\n",
    "# no2.index.hour\n",
    "no2.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and what is more interesting, I can change the sampling frequency\n",
    "no2.resample('D').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there any seasonality?\n",
    "no2.resample('M').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long term trend?\n",
    "no2.resample('A').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly seasonality?\n",
    "no2['2012-3':'2012-4'].resample('D').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can also use several aggregation functions and compare them\n",
    "no2.loc['2009':, 'FR04037'].resample('M').agg(['mean', 'median']).plot()\n",
    "# no2.loc['2009':, 'FR04037'].resample('M').agg(['mean', 'std']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention resample != groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a time course with monthly granularity. The values ​​are averaged over the course of the month\n",
    "no2.resample('M').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the average of all values ​​for the month with the given number. Even over the years.\n",
    "# So I got the average course of the value over the year with monthly granularity.\n",
    "no2.groupby(no2.index.month).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary, what to take away from this EDA\n",
    "\n",
    "* Make sure that the data is coded correctly (most often you have to look into the data manually)\n",
    "* Make sure the data falls within the expected range and all have the expected shape (for example time format)\n",
    "* Never change the data manually. Always use a code that you save and use every time you repeat the experiment. We want the analysis to be reproducible\n",
    "* Graph everything you can to visually confirm that something is as it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
